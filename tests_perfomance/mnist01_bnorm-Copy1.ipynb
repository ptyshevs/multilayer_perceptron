{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from nn import *\n",
    "from viz import plot_history\n",
    "from tools import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.01249992e-07, -1.01249992e-07,  2.02499984e-07],\n",
       "        [-3.37499990e-08,  0.00000000e+00,  3.37499990e-08]]),\n",
       " array([[2.99999987, 2.99999993]]),\n",
       " array([[2.22044605e-16, 0.00000000e+00]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0, 1],\n",
    "              [0, 2],\n",
    "              [1, 3]])\n",
    "\n",
    "b = BatchNorm()\n",
    "b._initialize(X.shape)\n",
    "y = b.forward_propagate(X)\n",
    "b.backward_propagate(y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = NeuralNetwork('binary_crossentropy', 'adam', verbose=True, verbose_step=1)\n",
    "m.add(Dense(30, 'relu'))\n",
    "m.add(BatchNorm())\n",
    "m.add(Dense(1, 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(1000, 30)\n",
    "Y = np.random.binomial(1, .5, size=(1000, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1/100]: loss=0.68095 \n",
      "[    2/100]: loss=0.65852 \n",
      "[    3/100]: loss=0.62714 \n",
      "[    4/100]: loss=0.59535 \n",
      "[    5/100]: loss=0.56421 \n",
      "[    6/100]: loss=0.53414 \n",
      "[    7/100]: loss=0.51253 \n",
      "[    8/100]: loss=0.49299 \n",
      "[    9/100]: loss=0.47464 \n",
      "[   10/100]: loss=0.46559 \n",
      "[   11/100]: loss=0.44728 \n",
      "[   12/100]: loss=0.43640 \n",
      "[   13/100]: loss=0.44461 \n",
      "[   14/100]: loss=0.43027 \n",
      "[   15/100]: loss=0.44290 \n",
      "[   16/100]: loss=0.43375 \n",
      "[   17/100]: loss=0.42188 \n",
      "[   18/100]: loss=0.46085 \n",
      "[   19/100]: loss=0.46883 \n",
      "[   20/100]: loss=0.45820 \n",
      "[   21/100]: loss=0.48687 \n",
      "[   22/100]: loss=0.49817 \n",
      "[   23/100]: loss=0.51335 \n",
      "[   24/100]: loss=0.54078 \n",
      "[   25/100]: loss=0.47804 \n",
      "[   26/100]: loss=0.51825 \n",
      "[   27/100]: loss=0.51766 \n",
      "[   28/100]: loss=0.55155 \n",
      "[   29/100]: loss=0.51332 \n",
      "[   30/100]: loss=0.51107 \n",
      "[   31/100]: loss=0.46344 \n",
      "[   32/100]: loss=0.51537 \n",
      "[   33/100]: loss=0.51038 \n",
      "[   34/100]: loss=0.45464 \n",
      "[   35/100]: loss=0.45104 \n",
      "[   36/100]: loss=0.54667 \n",
      "[   37/100]: loss=0.51447 \n",
      "[   38/100]: loss=0.53632 \n",
      "[   39/100]: loss=0.61837 \n",
      "[   40/100]: loss=0.63551 \n",
      "[   41/100]: loss=0.56649 \n",
      "[   42/100]: loss=0.61507 \n",
      "[   43/100]: loss=0.62718 \n",
      "[   44/100]: loss=0.61742 \n",
      "[   45/100]: loss=0.74374 \n",
      "[   46/100]: loss=0.63716 \n",
      "[   47/100]: loss=0.62709 \n",
      "[   48/100]: loss=0.62224 \n",
      "[   49/100]: loss=0.61284 \n",
      "[   50/100]: loss=0.55649 \n",
      "[   51/100]: loss=0.57629 \n",
      "[   52/100]: loss=0.54983 \n",
      "[   53/100]: loss=0.55604 \n",
      "[   54/100]: loss=0.56406 \n",
      "[   55/100]: loss=0.57273 \n",
      "[   56/100]: loss=0.57893 \n",
      "[   57/100]: loss=0.58689 \n",
      "[   58/100]: loss=0.59349 \n",
      "[   59/100]: loss=0.60066 \n",
      "[   60/100]: loss=0.60658 \n",
      "[   61/100]: loss=0.61444 \n",
      "[   62/100]: loss=0.62088 \n",
      "[   63/100]: loss=0.62725 \n",
      "[   64/100]: loss=0.63343 \n",
      "[   65/100]: loss=0.63889 \n",
      "[   66/100]: loss=0.64476 \n",
      "[   67/100]: loss=0.65073 \n",
      "[   68/100]: loss=0.65566 \n",
      "[   69/100]: loss=0.66115 \n",
      "[   70/100]: loss=0.66776 \n",
      "[   71/100]: loss=0.67195 \n",
      "[   72/100]: loss=0.67781 \n",
      "[   73/100]: loss=0.68343 \n",
      "[   74/100]: loss=0.68787 \n",
      "[   75/100]: loss=0.69316 \n",
      "[   76/100]: loss=0.69859 \n",
      "[   77/100]: loss=0.70299 \n",
      "[   78/100]: loss=0.70885 \n",
      "[   79/100]: loss=0.71324 \n",
      "[   80/100]: loss=0.71871 \n",
      "[   81/100]: loss=0.72363 \n",
      "[   82/100]: loss=0.72797 \n",
      "[   83/100]: loss=0.73175 \n",
      "[   84/100]: loss=0.73688 \n",
      "[   85/100]: loss=0.74059 \n",
      "[   86/100]: loss=0.74549 \n",
      "[   87/100]: loss=0.74957 \n",
      "[   88/100]: loss=0.75396 \n",
      "[   89/100]: loss=0.75822 \n",
      "[   90/100]: loss=0.76289 \n",
      "[   91/100]: loss=0.76679 \n",
      "[   92/100]: loss=0.77115 \n",
      "[   93/100]: loss=0.77502 \n",
      "[   94/100]: loss=0.77976 \n",
      "[   95/100]: loss=0.78357 \n",
      "[   96/100]: loss=0.78698 \n",
      "[   97/100]: loss=0.79088 \n",
      "[   98/100]: loss=0.79490 \n",
      "[   99/100]: loss=0.79780 \n",
      "[  100/100]: loss=0.80241 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History: epoch|loss"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(X, Y, batch_size=32, n_epochs=100, reinitialize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.59710084, 2.45464589, 1.87317133, 2.68688639, 2.64712389,\n",
       "        2.36976416, 2.70427776, 2.73380745, 2.12671323, 2.76991648,\n",
       "        2.86989744, 2.77922852, 2.44794904, 2.41728062, 2.61233974,\n",
       "        2.62451709, 2.12074598, 1.99250797, 2.15363893, 2.57641761,\n",
       "        2.33674048, 2.79490141, 2.49628351, 2.90693216, 2.85601627,\n",
       "        2.6414463 , 2.73711393, 2.42949819, 2.93107336, 2.69953227]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.layers[1].gammas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
